{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "name": "1.6 Pivot table",
    "notebookId": 89637,
    "colab": {
      "name": "1.6 Pivot table.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH-CCmYD-lWa",
        "colab_type": "text"
      },
      "source": [
        "# THIS NOTEBOOK HAS NOT BEEN UPDATED FOR COLAB \n",
        "# AND SO DOES NOT WORK --- SORRY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZouzyfb8LgM",
        "colab_type": "text"
      },
      "source": [
        "# `pandas` - Reshaping Data and Pivots tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3B6XkY8LgP",
        "colab_type": "text"
      },
      "source": [
        "__Contents__\n",
        "1. Setup\n",
        "1. Reshaping data by pivoting/melt/stacking and unstacking\n",
        "1. Pivot tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMqgR_xN8LgP",
        "colab_type": "text"
      },
      "source": [
        "##Reference\n",
        "Related/useful documentation:\n",
        "- http://pandas.pydata.org/pandas-docs/stable/index.html\n",
        "- https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31DhimVC8LgQ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEtFbwy28LgR",
        "colab_type": "text"
      },
      "source": [
        "Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8nl6Oi18LgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "319e893a-2a61-4ef8-ee5a-831b9584b0e2"
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy   as np\n",
        "(pd.__version__,\n",
        " np.__version__\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0.25.3', '1.17.5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTY7p2hn8LgU",
        "colab_type": "text"
      },
      "source": [
        "Load a DataFrame from the `imports-85.csv` CSV file. Set the column names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBbcpbtM8LgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "1257fe47-b6cb-4d0e-c108-3f12bc7615c6"
      },
      "source": [
        "column_names = ['symboling', 'normalized-losses', 'make', 'fuel-type',\n",
        "                'aspiration', 'num-of-doors', 'body-style', 'drive-wheels',\n",
        "                'engine-location', 'wheel-base', 'length', 'width',\n",
        "                'height', 'curb-weight', 'engine-type', 'num-of-cylinders',\n",
        "                'engine-size', 'fuel-system', 'bore', 'stroke',\n",
        "                'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
        "                'highway-mpg', 'price']\n",
        "import_df = pd.read_csv('/dbfs/mnt/datalab-datasets/file-samples/imports-85.csv',\n",
        "                        names=[string.replace('-','_') for string in column_names],\n",
        "                        na_values=['?']\n",
        "                       )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-71a5ea0eb6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m import_df = pd.read_csv('/dbfs/mnt/datalab-datasets/file-samples/imports-85.csv',\n\u001b[1;32m      9\u001b[0m                         \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                        )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/dbfs/mnt/datalab-datasets/file-samples/imports-85.csv' does not exist: b'/dbfs/mnt/datalab-datasets/file-samples/imports-85.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqPCYNx98LgZ",
        "colab_type": "text"
      },
      "source": [
        "Display basic information about each column of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwZ1oG4U8LgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "b35614ea-0382-4e56-d55b-20d5bd9d50a3"
      },
      "source": [
        "import_df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-07a45ebe3a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimport_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'import_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr6LnOiY8Lgc",
        "colab_type": "text"
      },
      "source": [
        "Create another sample DataFrame `df` and display the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y7eR8jE8Lgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "np.random.seed(0)\n",
        "df = pd.DataFrame({'item': ['A']*6 + ['B']*6 + ['C']*6 + ['D']*6,\n",
        "                    'quantity': np.random.randint(1000,size=24),\n",
        "                    'value': np.random.randn(24),\n",
        "                    'date': [datetime.datetime(2013, i, 1) for i in range(1, 7)]*4\n",
        "                   })\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxrjUM_u8Lgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "np.random.seed(1)\n",
        "icecream_sales = pd.DataFrame({'flavor': ['Chocolate']*6 + ['Vanilla']*6 + ['Cookie Dough']*6 + ['Green Tea']*6,\n",
        "                    'quantity': np.random.randint(10,size=24)+1,\n",
        "                    'profit': 1.5*np.random.random_integers(5,size=24),\n",
        "                    'date': [datetime.datetime(2018, 4, i) for i in range(1, 7)]*4\n",
        "                   })\n",
        "icecream_sales.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OeWEERJ8Lgh",
        "colab_type": "text"
      },
      "source": [
        "##2. Reshaping data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWxDcTdv8Lgi",
        "colab_type": "text"
      },
      "source": [
        "### `pivot()` method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRjO8X08Lgk",
        "colab_type": "text"
      },
      "source": [
        "The `pivot()` method of a DataFrame object is used to create a new derived table out of the given one. `pivot()` method takes 3 arguements: \n",
        "- `index` \n",
        "- `columns` \n",
        "- `values`\n",
        "\n",
        "Notice that we cannot aggregate using `pivot()` method and if either rows or columns are not unique, this method will fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfRCMOAT8Lgm",
        "colab_type": "text"
      },
      "source": [
        "Use `pivot` method to reshape the data into a time series format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKH0e1lV8Lgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pivot_df = icecream_sales.pivot(index='date', columns='flavor', values='quantity')\n",
        "pivot_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTADekQm8Lgr",
        "colab_type": "text"
      },
      "source": [
        "Pivoting by multiple columns. Notice that in `pivot` method, if not specify the `values` parameter, all remaining columns will be used and the result will have hierarchically indexed columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRWl5mm68Lgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icecream_sales.pivot(index='date',columns='flavor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMHfK5BY8Lgu",
        "colab_type": "text"
      },
      "source": [
        "##`melt()` function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyqqhUzZ8Lgu",
        "colab_type": "text"
      },
      "source": [
        "The `melt()` function and the `melt()` method of a DataFrame are useful to transform a DataFrame from wide to long format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvRfQqbx8Lgv",
        "colab_type": "text"
      },
      "source": [
        "Create numeric index in the `pivot_df` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROgp9y6u8Lgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pivot_df.reset_index(inplace = True)\n",
        "pivot_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUcoTMJh8Lg0",
        "colab_type": "text"
      },
      "source": [
        "Use the `melt()` function to reshape the `pivot_df` DataFrame. The `melt()` function in the below code cell takes \n",
        "- `pivot_df`: the name of dataframe to reshape\n",
        "- `id_vars` : the column(s) to use as identifier variable(s)\n",
        "- `var_name`: name to use for the ‘variable’ column\n",
        "- `value_name`: name to use for the ‘value’ column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN7ZxSg88Lg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.melt(pivot_df,id_vars=['date'],var_name='flavor',value_name='sales')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT4KPQ7h8Lg8",
        "colab_type": "text"
      },
      "source": [
        "### `stack()` & `unstack()` method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hVvTdZ-8Lg9",
        "colab_type": "text"
      },
      "source": [
        "The `stack` and `unstack` methods are designed to work together with MultiIndex objects. Create a MultiIndex object `df_multi` from the `icecream_sales` DataFrame by setting multiple indexes and sorting them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q1Czk0s8Lg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_multi = icecream_sales.set_index(['date','flavor']).sort_index()\n",
        "df_multi.head(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq4qT9fZ8LhA",
        "colab_type": "text"
      },
      "source": [
        "The `stack()` method “compresses”(stack) a level in the `df_multi`’s columns. The stacked level becomes the new lowest level in a MultiIndex on the columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cHVB-KL8LhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_multi.stack()\\\n",
        "        .rename_axis(['date','flavor','type'],axis=0)\\\n",
        "        .head(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNDbG1O8LhD",
        "colab_type": "text"
      },
      "source": [
        "With a “stacked” DataFrame, the inverse operation of stack is unstack, which by default unstacks the last level:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSiwVcNX8LhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_multi.stack()\\\n",
        "        .rename_axis(['date','flavor','type'],axis=0)\\\n",
        "        .unstack()\\\n",
        "        .head(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQflUsag8LhR",
        "colab_type": "text"
      },
      "source": [
        "The `stack()` or `unstack()` method can be applied to more than one level at a time by passing a list of levels. In the code cell below we pass a list of column names to the `unstack()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsc20ULo8LhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_multi.stack()\\\n",
        "        .rename_axis(['date','flavor','type'],axis=0)\\\n",
        "        .unstack(['flavor','type'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIK0xBqM8LhU",
        "colab_type": "text"
      },
      "source": [
        "##3. Pivot tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTILG7xa8LhU",
        "colab_type": "text"
      },
      "source": [
        "While `pivot()` provides general purpose pivoting with various data types (strings, numerics, etc.), pandas also provides `pivot_table()` for pivoting with aggregation of numeric data. The `pivot_table` method works like `pivot()`, but it aggregates the values from rows with duplicate entries for the specified columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEkHZtQ98LhV",
        "colab_type": "text"
      },
      "source": [
        "Create a `pivot_table` instance of a DataFrame object:\n",
        "- The `data` arguments takes a DataFrame object.\n",
        "- The `index` and `columns` arguments take categorical variables which have duplicate values in the DataFrame. \n",
        "- The `values` arguments takes variable(s) that can be aggregated. \n",
        "- The `aggfunc` arguments takes the function to use for aggregation, defaulting to `numpy.mean`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_UnMk4J8LhV",
        "colab_type": "text"
      },
      "source": [
        "Create a pivot table from the `import_df` DataFrame. In the pivot table we calculate the average `horsepower` for each `body_style` according to the type of `drive_wheels`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vBujQQ_8LhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.pivot_table(data=import_df, index='body_style', columns='drive_wheels', values='horsepower', aggfunc=np.mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve0NyCOr8Lhc",
        "colab_type": "text"
      },
      "source": [
        "Below, create a pivot table from the `import_df` DataFrame that calculates the average `price` for each `body_style`. The result object `res` is a Series. The values are rounded to zero decimals usingthe `np.round()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6XKwU888Lhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.pivot_table(import_df, \n",
        "                     values ='price', \n",
        "                     index='body_style',\n",
        "                     aggfunc=np.mean)\n",
        "np.round(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt1hJBCU8Lhf",
        "colab_type": "text"
      },
      "source": [
        "Create a pivot table from the `import_df` DataFrame. The result object `res` is a DataFrame having hierarchical indexes on the rows. Omit the missing values by calling `to_string` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Xenbq08Lhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.pivot_table(import_df, \n",
        "                     values ='price', \n",
        "                     columns='body_style', \n",
        "                     index  =['make','drive_wheels'], \n",
        "                     aggfunc=np.mean)\\\n",
        "        .round()\n",
        "\n",
        "print(res.to_string(na_rep=''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfQRw6Vp8Lhi",
        "colab_type": "text"
      },
      "source": [
        "Note that `pivot_table` is also available as an instance method on DataFrame, i.e. `DataFrame.pivot_table()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZA4EdFq8Lhi",
        "colab_type": "text"
      },
      "source": [
        "Create a pivot table from `import_df` by calling the `pivot_table` method. \n",
        "Since the `values` column name is not given, after grouping by the `make` variable, all columns are aggregated using the `np.mean` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsFg1Vl98Lhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import_df.pivot_table(index='make').round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pD5Kqhu8Lhl",
        "colab_type": "text"
      },
      "source": [
        "Note that the following command cell has the same output as the above one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corc9dXS8Lhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.pivot_table(import_df, index='make').round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoAGJtEh8Lhn",
        "colab_type": "text"
      },
      "source": [
        "__The End__"
      ]
    }
  ]
}