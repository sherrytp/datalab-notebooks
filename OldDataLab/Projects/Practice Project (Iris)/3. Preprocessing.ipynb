{"cells":[{"cell_type":"markdown","source":["d #The Classification of Iris Flowers \n \n ##Preprocessing"],"metadata":{}},{"cell_type":"markdown","source":["## Table of Contents\n\n1. Setup\n1. Split data\n1. Standardize feature data\n1. Encode categorical label data"],"metadata":{}},{"cell_type":"markdown","source":["##1. Setup"],"metadata":{}},{"cell_type":"markdown","source":["###1.1 Import libraries"],"metadata":{}},{"cell_type":"markdown","source":["Check the versions of libraries."],"metadata":{}},{"cell_type":"code","source":["import sys\nimport numpy as np\nimport matplotlib \nimport pandas as pd\nimport sklearn as sk\nprint('Python: {}'.format(sys.version))\nprint('numpy: {}'.format(np.__version__))\nprint('matplotlib: {}'.format(matplotlib.__version__))\nprint('pandas: {}'.format(pd.__version__))\nprint('sklearn: {}'.format(sk.__version__))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python: 3.5.2 (default, Nov 23 2017, 16:37:01) \n[GCC 5.4.0 20160609]\nnumpy: 1.14.5\nmatplotlib: 1.5.3\npandas: 0.19.2\nsklearn: 0.18.1\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Import all of the modules, functions and objects we are going to use in this project."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["###1.2 Load the data"],"metadata":{}},{"cell_type":"markdown","source":["Load the iris data from CSV file."],"metadata":{}},{"cell_type":"code","source":["import_df = pd.read_csv('/dbfs/mnt/datalab-datasets/file-samples/iris.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["###1.3 Peek at the data"],"metadata":{}},{"cell_type":"markdown","source":["Look at the first few rows of data using the `head()` method of the `import_df` dataframe."],"metadata":{}},{"cell_type":"code","source":["import_df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">32</span><span class=\"ansired\">]: </span>\n   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n0          5.1         3.5          1.4         0.2  Iris-setosa\n1          4.9         3.0          1.4         0.2  Iris-setosa\n2          4.7         3.2          1.3         0.2  Iris-setosa\n3          4.6         3.1          1.5         0.2  Iris-setosa\n4          5.0         3.6          1.4         0.2  Iris-setosa\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Figure out the features and the target variable:\n- Quantitative Features (Numerical): `SepalLength`, `SepalWidth`, `PetalLength`, `PetalWidth`.\n- Target Variable (Categorical): `Name`."],"metadata":{}},{"cell_type":"markdown","source":["##2. Split data"],"metadata":{}},{"cell_type":"markdown","source":["###2.1 Split data into features and target"],"metadata":{}},{"cell_type":"markdown","source":["Create a variable for the feature data."],"metadata":{}},{"cell_type":"code","source":["X = import_df.values[:,0:4]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["__Exercise 1__ Create a variable `y` for the target data. \n\n__[Its not clear from the above text in the notebook that column `4` is the target variable.]__\n\n__Rita: The section `1.3 Peek at the data` is added (from Cmd 12-15) to figure out the features and target first.__"],"metadata":{}},{"cell_type":"code","source":["y = import_df.values[:,4]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["###2.2 Split data for cross validation"],"metadata":{}},{"cell_type":"markdown","source":["__Exercise 2__ Use the function `train_test_split` to split the data into four new datasets, training features `X_train`, training target `y_train`, test features `X_test`, and test target `y_test`. Set the size of the test data to be 30% of the full dataset. Use `random_state=42` to reproduce the same outcome.\n\n__[What do you think about making this into an exercise? For instance, \"Use the function `train_test_split` to split the data into four ...\"]__\n\n__Rita: This is an exercise now.__"],"metadata":{}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["##3. Standardize feature data"],"metadata":{}},{"cell_type":"markdown","source":["Load the standard scaler."],"metadata":{}},{"cell_type":"code","source":["sc = StandardScaler()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["__Exercise 3__ Call the `fit` method of the object `sc` on the training feature data. Specifically, the `fit` method computes the mean and standard deviation of each column based on the training data."],"metadata":{}},{"cell_type":"code","source":["sc.fit(X_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n  warnings.warn(msg, _DataConversionWarning)\n<span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>StandardScaler(copy=True, with_mean=True, with_std=True)\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["Call the `transform` method of the object `sc` on the training feature data. Specifically, the `transform` method subtracts the mean of each column and then divides by the standard deviation. Scale the training data to be of mean 0 and of unit variance.\n\n__[You might indicate what the `transform` method does (subtract mean of column and then divide by standard deviation) and then note that the resulting columns have mean 0 and variance  of `1`. Does it have unit variance or unit standard deviation?]__\n\n__Rita : I edit this cell to indicate what the `transform` method does, and add two cells below (Cmd 32-33) to show the results. \n_For the last question, the transformed columns must have variance = 1, and the standard deviation will also be 1 since it is the square root of the variance. The documentation of `StandardScaler` uses 'unit variance'. http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler_ __"],"metadata":{}},{"cell_type":"code","source":["X_train_std = sc.transform(X_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n  warnings.warn(msg, _DataConversionWarning)\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["Note that the resulting columns of the training data have mean 0 and of unit variance."],"metadata":{}},{"cell_type":"code","source":["X_train_std.mean(axis=0), X_train_std.std(axis=0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">35</span><span class=\"ansired\">]: </span>\n(array([ 2.57148800e-15, -1.09441226e-15, -2.70682947e-16, -9.72766841e-17]),\n array([1., 1., 1., 1.]))\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["__Exercise 4__ Scale the test data to be of mean 0 and of unit variance. Store the transformed data in a variable `X_test_std`."],"metadata":{}},{"cell_type":"code","source":["X_test_std = sc.transform(X_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["##4. Encode categorical target data"],"metadata":{}},{"cell_type":"markdown","source":["__Exercise 5__ Load the label encoder and store it in an object `le`. `LabelEncoder` is an utility class to transform non-numerical labels to numerical labels with values between 0 and n_classes-1."],"metadata":{}},{"cell_type":"code","source":["le = LabelEncoder()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["Use the `fit` method of the `le` object to compute the number of classes based on the training target data."],"metadata":{}},{"cell_type":"code","source":["le.fit(y_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>LabelEncoder()\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["Normalizes the training target data to be values between 0 and n_classes-1."],"metadata":{}},{"cell_type":"code","source":["y_train_num = le.transform(y_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["__Exercise 6__ Use the `transform` method of the `le` object to normalize the testing target data, and store the transformed data into a variable `y_test_num`.\n\n__[When creating variables you have two goals: 1. make the variable short, 2. make them easy to remember. I am tending toward 3 letter names and in this case would try `lab_enc` and `std_sca` for the previous one.]__\n\n__Rita: I agree the variable names I used are not good, but I also want to clearly spercify the training and testing set. `lab_enc` may mix the difference between train and test.__"],"metadata":{}},{"cell_type":"code","source":["y_test_num = le.transform(y_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["We now have training data in the `X_train_std` and `y_train_num` for preparing models and a `X_test_std` and `y_test_num` sets that we can use to evaluate the models."],"metadata":{}},{"cell_type":"markdown","source":["##__Exercise:__ \n\nUse a new dataset (try the Pima Indians dataset) to practice the methods introduced in the notebook.\n\n- Check the Pima Indians dataset (https://www.kaggle.com/uciml/pima-indians-diabetes-database). \nThe csv file can be found under the directory of `datalab-datasets` as displayed in the cell below."],"metadata":{}},{"cell_type":"code","source":["%sh ls /dbfs/mnt/datalab-datasets/file-samples/pima-indians-diabetes.csv"],"metadata":{},"outputs":[],"execution_count":47}],"metadata":{"name":"3. Preprocessing","notebookId":2866233958142639},"nbformat":4,"nbformat_minor":0}
